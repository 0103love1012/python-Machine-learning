SVM支持向量机算法：支持向量回归(SVM_SVR);支持向量分类(SVM_SVR)

参考https://www.cnblogs.com/harvey888/p/5852687.html
   https://blog.csdn.net/lisi1129/article/details/70209945?locationNum=8&fps=1

核函数实质：实际中，我们会经常遇到线性不可分的样例，此时，我们的常用做法是把样例特征映射到高维空间中去，
            但进一步，如果凡是遇到线性不可分的样例，一律映射到高维空间，那么这个维度大小是会高到可怕的
           此时，核函数就隆重登场了，核函数的价值在于它虽然也是讲特征进行从低维到高维的转换，但核函数绝就绝在它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，              也就如上文所说的避免了直接在高维空间中的复杂计算。详细见https://blog.csdn.net/leonis_v/article/details/50688766

SVM关键是选取核函数的类型，主要有线性内核，多项式内核，径向基内核（RBF），sigmoid核,至于怎样选取请看https://www.zhihu.com/question/21883548

在支持向量分类(SVM_SVR)仅试验了线性内核和径向基内核（RBF）

   
   